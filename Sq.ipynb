{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PARALLELIZE RANDOM FOREST"
      ],
      "metadata": {
        "id": "7vpdloU5lbkm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hàm hỗ trợ"
      ],
      "metadata": {
        "id": "nrZgqWvz6eig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import time\n",
        "from numba import prange, njit, jit, typed, types\n",
        "from numba.typed import List, Dict\n",
        "from numba.core import types\n",
        "\n",
        "# To ignore warinings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "fftBSw4ufDXo"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "GzG3pa9aHAcP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c91b283-14e5-437c-e48c-b1c594baf123"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hàm hỗ trợ phân tách tập train - test\n",
        "\n",
        "def trainTestSplit(dataFrame, testSize):\n",
        "    if isinstance(testSize, float):\n",
        "        testSize = round(testSize * len(dataFrame))\n",
        "    indices = dataFrame.index.tolist()\n",
        "    testIndices = random.sample(population = indices, k = testSize)\n",
        "    dataFrameTest = dataFrame.loc[testIndices]\n",
        "    dataFrameTrain = dataFrame.drop(testIndices)\n",
        "    return dataFrameTrain, dataFrameTest"
      ],
      "metadata": {
        "id": "guIv9IUD6eOj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sequential V1"
      ],
      "metadata": {
        "id": "BeNbGTUI1L-Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Tree\n"
      ],
      "metadata": {
        "id": "mn_Zumfi1VDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Kiểm tra data có thuộc một label duy nhất\n",
        "'''\n",
        "def checkPurity(data):\n",
        "    if len(np.unique(data[:, -1])) == 1:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "\n",
        "'''\n",
        "Xác định label phổ biến nhất còn trong data và trả về label đó\n",
        "\n",
        "'''\n",
        "def classifyData(data):\n",
        "    uniqueClasses, uniqueClassesCounts = np.unique(data[:, -1], return_counts = True)\n",
        "    return uniqueClasses[uniqueClassesCounts.argmax()]\n",
        "\n",
        "\n",
        "'''\n",
        "Xác định cột (thuộc tính) và các giá trị split tiềm năng của cột đó\n",
        "'''\n",
        "# def getPotentialSplits(data):\n",
        "#     potentialSplits = {}\n",
        "#     _, columns = data.shape\n",
        "\n",
        "#     # Lấy hết thuộc tính (trừ cột label cuối cùng) gán vào columnsIndices (List gồm index của các thuộc tính)\n",
        "#     columnsIndices = list(range(columns - 1))\n",
        "\n",
        "#     for column in columnsIndices:\n",
        "#         values = data[:, column]\n",
        "#         # Xét độ unique của mỗi thuộc tính\n",
        "#         uniqueValues = np.unique(values)\n",
        "\n",
        "#         # Nếu thuộc tính chỉ có đúng 1 giá trị thì potentialSplits tại cột (thuộc tính) đó = chính giá trị đó\n",
        "#         if len(uniqueValues) == 1:\n",
        "#             potentialSplits[column] = uniqueValues\n",
        "\n",
        "#         # còn không thì potentialSplits tại cột (thuộc tính) đó sẽ chứa các giá trị trung bình giữa 2 giá trị kế nhau trong mảng uniqueValues\n",
        "#         else:\n",
        "#             potentialSplits[column] = []\n",
        "#             for i in range(len(uniqueValues)):\n",
        "#                 if i != 0:\n",
        "#                     currentValue = uniqueValues[i]\n",
        "#                     previousValue = uniqueValues[i - 1]\n",
        "#                     potentialSplits[column].append((currentValue + previousValue) / 2)\n",
        "#     return potentialSplits\n",
        "\n",
        "\n",
        "def getPotentialSplits(data):\n",
        "  columns = data.shape[1]\n",
        "\n",
        "\n",
        "  columnsIndices = np.arange(columns - 1)\n",
        "  potentialSplits = np.empty(columns - 1, dtype=object)\n",
        "\n",
        "  for col in columnsIndices:\n",
        "    values = data[:, col]\n",
        "\n",
        "    uniqueValues = np.unique(values)\n",
        "\n",
        "    if len(uniqueValues) == 1:\n",
        "      potentialSplits[col] = uniqueValues\n",
        "\n",
        "    else:\n",
        "      splitValues = np.empty(len(uniqueValues - 1))\n",
        "\n",
        "      for i in range(len(uniqueValues)):\n",
        "          if i != 0:\n",
        "              currentValue = uniqueValues[i]\n",
        "              previousValue = uniqueValues[i - 1]\n",
        "              splitValues[i-1] = (currentValue + previousValue) / 2\n",
        "\n",
        "      # Vẫn là mảng một chiều nên access vô phần tử bằng [][] còn [ , ] thì ko dc\n",
        "      potentialSplits[col] = splitValues\n",
        "\n",
        "  return potentialSplits\n",
        "\n",
        "\n",
        "'''\n",
        "# Tách data thành 2 phần dựa vào splitValue\n",
        "'''\n",
        "\n",
        "def splitData(data, splitColumn, splitValue):\n",
        "    # Lấy data của cột thuộc tính đang đc xét để so sánh\n",
        "    splitColumnValues = data[:, splitColumn]\n",
        "\n",
        "    # Tách nguyên data (không phải chỉ mỗi data ở cột splitColumnValues) thành hai phần, một phần gồm các giá trị ở cột splitColumnValues <= splitValue và ngược lại\n",
        "    return data[splitColumnValues <= splitValue], data[splitColumnValues > splitValue]\n",
        "\n",
        "'''\n",
        "# Tính entropy của từng phần data\n",
        "'''\n",
        "\n",
        "def calculateEntropy(data):\n",
        "    # Tính entropy của data dựa vào tỷ lệ labels mà data thuộc về\n",
        "    _, uniqueClassesCounts = np.unique(data[:, -1], return_counts = True)\n",
        "    probabilities = uniqueClassesCounts / uniqueClassesCounts.sum()\n",
        "    return sum(probabilities * -np.log2(probabilities))\n",
        "\n",
        "\n",
        "'''\n",
        "# Tính tổng entropy\n",
        "'''\n",
        "\n",
        "def calculateOverallEntropy(dataBelow, dataAbove):\n",
        "    # Lấy tỷ lệ số lượng data ở nửa trên so với số lượng data\n",
        "\n",
        "    pDataBelow = len(dataBelow) / (len(dataBelow) + len(dataAbove))\n",
        "\n",
        "    # Lấy tỷ lệ số lượng data ở nửa dưới so với số lượng data\n",
        "    pDataAbove = len(dataAbove) / (len(dataBelow) + len(dataAbove))\n",
        "    return pDataBelow * calculateEntropy(dataBelow) + pDataAbove * calculateEntropy(dataAbove)\n",
        "\n",
        "\n",
        "'''\n",
        "Xác định cột (thuộc tính) và giá trị tiềm năng duy nhất của cột đó (splitPoint có entropy nhỏ nhất)\n",
        "'''\n",
        "# def determineBestSplit(data, potentialSplits):\n",
        "#     overallEntropy = 9999\n",
        "#     bestSplitColumn = 0\n",
        "#     bestSplitValue = 0\n",
        "\n",
        "#     # Xét từng key là thuộc tính trong potentialSplits\n",
        "#     for splitColumn in potentialSplits:\n",
        "#         # Xét từng value của từng thuộc tính trong potentialSplits\n",
        "#         for splitValue in potentialSplits[splitColumn]:\n",
        "#             # Tách nguyên data của làm hai phần nhỏ hơn và lớn hơn so với value đang xét\n",
        "#             dataBelow, dataAbove = splitData(data, splitColumn, splitValue)\n",
        "#             # Xét Entropy của 2 phần data đó, nếu nhỏ nhất thì lấy\n",
        "#             currentOverallEntropy = calculateOverallEntropy(dataBelow, dataAbove)\n",
        "#             if currentOverallEntropy <= overallEntropy:\n",
        "#                 overallEntropy = currentOverallEntropy\n",
        "#                 bestSplitColumn = splitColumn\n",
        "#                 bestSplitValue = splitValue\n",
        "#     return bestSplitColumn, bestSplitValue\n",
        "\n",
        "\n",
        "def determineBestSplit(data, potentialSplits):\n",
        "    overallEntropy = 9999\n",
        "    bestSplitColumn = 0\n",
        "    bestSplitValue = 0\n",
        "\n",
        "    # Xét từng key là thuộc tính trong potentialSplits\n",
        "    for splitColumn in range(len(potentialSplits)):\n",
        "        # Xét từng value của từng thuộc tính trong potentialSplits\n",
        "        for splitValue in range(len(potentialSplits[splitColumn])):\n",
        "            # Tách nguyên data của làm hai phần nhỏ hơn và lớn hơn so với value đang xét\n",
        "            dataBelow, dataAbove = splitData(data, splitColumn, splitValue)\n",
        "            # Xét Entropy của 2 phần data đó, nếu nhỏ nhất thì lấy\n",
        "            currentOverallEntropy = calculateOverallEntropy(dataBelow, dataAbove)\n",
        "            if currentOverallEntropy <= overallEntropy:\n",
        "                overallEntropy = currentOverallEntropy\n",
        "                bestSplitColumn = splitColumn\n",
        "                bestSplitValue = splitValue\n",
        "    return bestSplitColumn, bestSplitValue\n",
        "\n",
        "\n",
        "'''\n",
        "Xây dựng cây\n",
        "'''\n",
        "def buildDecisionTree(dataFrame, currentDepth = 0, minSampleSize = 2, maxDepth = 1000):\n",
        "    # Nếu mới bắt đầu khởi tạo cây\n",
        "    if currentDepth == 0:\n",
        "        global COLUMN_HEADERS\n",
        "        COLUMN_HEADERS = dataFrame.columns.to_numpy()\n",
        "        data = dataFrame.to_numpy()\n",
        "    else:\n",
        "        data = dataFrame\n",
        "    # Xét nếu tất cả dữ liệu đều có label giống nhau || dữ liệu dữ liệu ít hơn số dữ liệu tối thiểu để xét cho một node || độ cao đã đạt tối đa\n",
        "    if checkPurity(data) or len(data) < minSampleSize or currentDepth == maxDepth:\n",
        "        # Trả về label cho node cuối cùng đó\n",
        "        return classifyData(data)\n",
        "\n",
        "    # Nếu không thì tiếp tục quá trình tạo cây\n",
        "    else:\n",
        "        currentDepth += 1\n",
        "\n",
        "        # Lấy ra potentialSplits là dictionaries gồm key là các thuộc tính, values là các giá trị potential của mỗi thuộc tính\n",
        "        potentialSplits = getPotentialSplits(data)\n",
        "        # Lấy ra cột thuộc tính và giá trị split của thuộc tính mà mang lại giá trị entropy nhỏ nhất\n",
        "        splitColumn, splitValue = determineBestSplit(data, potentialSplits)\n",
        "\n",
        "        # split data theo 2 giá trị vừa lấy đc\n",
        "        dataBelow, dataAbove = splitData(data, splitColumn, splitValue)\n",
        "        # print(dataBelow)\n",
        "        # print('----------')\n",
        "        # print(dataAbove)\n",
        "\n",
        "        # Nếu tất cả data đều thuộc một label rồi thì lấy label đó cho node\n",
        "        if len(dataBelow) == 0 or len(dataAbove) == 0:\n",
        "            # print('YES')\n",
        "            return classifyData(data)\n",
        "        else:\n",
        "            # Đặt giá trị splitPoint cho thuộc tính đó, phần data nhỏ hơn sẽ qua yes và ngược lại\n",
        "            question = str(COLUMN_HEADERS[splitColumn]) + \" <= \" + str(splitValue)\n",
        "            decisionSubTree = {question: []}\n",
        "            # Tiếp tục rẽ nhánh bằng đệ quy\n",
        "            yesAnswer = buildDecisionTree(dataBelow, currentDepth, minSampleSize, maxDepth)\n",
        "            noAnswer = buildDecisionTree(dataAbove, currentDepth, minSampleSize, maxDepth)\n",
        "            # Nếu 2 nhánh giống nhau thì chỉ rẽ 1 nhánh, khác nhau thì rẽ 2 nhánh\n",
        "            if yesAnswer == noAnswer:\n",
        "                decisionSubTree = yesAnswer\n",
        "            else:\n",
        "                decisionSubTree[question].append(yesAnswer)\n",
        "                decisionSubTree[question].append(noAnswer)\n",
        "            return decisionSubTree\n",
        "\n",
        "\n",
        "'''\n",
        "Dùng để xét label cho tập dữ liệu bằng cách đưa mỗi cây trong randomForest\n",
        "'''\n",
        "def classifySample(sample, decisionTree):\n",
        "    # Nếu xét đến label của node lá cuối cùng thì trả về label đó\n",
        "    if not isinstance(decisionTree, dict):\n",
        "        return decisionTree\n",
        "    question = list(decisionTree.keys())[0]\n",
        "    attribute, value = question.split(\" <= \")\n",
        "    # So sánh với splitValue để mò đường đi tới node chứa label quyết định\n",
        "    if sample[attribute] <= float(value):\n",
        "        answer = decisionTree[question][0]\n",
        "    else:\n",
        "        answer = decisionTree[question][1]\n",
        "    return classifySample(sample, answer)\n",
        "\n",
        "\n",
        "'''\n",
        "Trả về label được dự đoán của tập data\n",
        "'''\n",
        "def decisionTreePredictions(dataFrame, decisionTree):\n",
        "    # Dự đoán từng label của từng dòng dữ liệu\n",
        "    predictions = dataFrame.apply(classifySample, axis = 1, args = (decisionTree,))\n",
        "    return predictions\n",
        "\n",
        "\n",
        "'''\n",
        "# So sánh độ chính xác giữa tập đang ktra và tập giá trị thật\n",
        "'''\n",
        "def calculateAccuracy(predictedResults, category):\n",
        "    resultCorrect = predictedResults == category\n",
        "    return resultCorrect.mean()"
      ],
      "metadata": {
        "id": "x9ZrleYU1QBa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest\n"
      ],
      "metadata": {
        "id": "vvdh5EPl1cf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Dùng kỹ thuật boostrap để lấy random một subset của data\n",
        "'''\n",
        "def bootstrapSample(dataFrame, bootstrapSize):\n",
        "    randomIndices = np.random.randint(low = 0, high = len(dataFrame), size = bootstrapSize)\n",
        "    return dataFrame.iloc[randomIndices]\n",
        "\n",
        "\n",
        "'''\n",
        "Xây dựng rừng cây từ các cây decision tree\n",
        "'''\n",
        "def createRandomForest(dataFrame, bootstrapSize, forestSize = 20, treeMaxDepth = 1000):\n",
        "    total_time=0\n",
        "    forest = []\n",
        "    for i in range(forestSize):\n",
        "        # Lấy random một subset của data bằng kỹ thuật boostrap\n",
        "        bootstrappedDataFrame = bootstrapSample(dataFrame, bootstrapSize)\n",
        "        # Xây dựng 1 cây quyết định từ subset đó\n",
        "        start_time = time.time()\n",
        "        decisionTree = buildDecisionTree(bootstrappedDataFrame, maxDepth = treeMaxDepth, )\n",
        "        end_time = time.time()\n",
        "        total_time += (end_time - start_time)\n",
        "        # Thêm cây vào rừng\n",
        "        forest.append(decisionTree)\n",
        "    print(\"AVG time to build a Decision Tree =\",total_time/forestSize)\n",
        "    return forest\n",
        "\n",
        "\n",
        "'''\n",
        "Dự đoán data bằng cách đưa qua từng cây trong randomForest rồi lấy label theo số đông\n",
        "'''\n",
        "def randomForestPredictions(dataFrame, randomForest):\n",
        "    predictions = {}\n",
        "    # Đưa dữ liệu qua rừng cây (cụ thể là từng cây)\n",
        "    for i in range(len(randomForest)):\n",
        "\n",
        "        column = \"decision tree \" + str(i)\n",
        "        predictions[column] = decisionTreePredictions(dataFrame, randomForest[i])\n",
        "    predictions = pd.DataFrame(predictions)\n",
        "    # Lấy label có số lần xuất hiện nhiều nhất của từng dòng\n",
        "    return predictions.mode(axis = 1)[0]\n",
        "\n",
        "'''\n",
        "# So sánh độ chính xác giữa tập đang ktra và tập giá trị thật\n",
        "'''\n",
        "def calculateAccuracy(predictedResults, category):\n",
        "    # So sánh label của tập dự đoán và tập real\n",
        "    resultCorrect = predictedResults == category\n",
        "    return resultCorrect.mean()"
      ],
      "metadata": {
        "id": "F2O5OGmr1ebm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run with car_evaluation dataset"
      ],
      "metadata": {
        "id": "MFSU5qttnOVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataFrame = pd.read_csv(\"/content/drive/MyDrive/Bài Tập Về Nhà Môn Cuối/random-forest-from-scratch-main/dataset_files/car_evaluation.csv\")\n",
        "\n",
        "buyingMapping = {\"low\": 1, \"med\": 2, \"high\": 3, \"vhigh\": 4}\n",
        "dataFrame[\"buying\"] = dataFrame[\"buying\"].map(buyingMapping)\n",
        "\n",
        "maintMapping = {\"low\": 1, \"med\": 2, \"high\": 3, \"vhigh\": 4}\n",
        "dataFrame[\"maint\"] = dataFrame[\"maint\"].map(maintMapping)\n",
        "\n",
        "doorsMapping = {\"2\": 2, \"3\": 3, \"4\": 4, \"5more\": 5}\n",
        "dataFrame[\"doors\"] = dataFrame[\"doors\"].map(doorsMapping)\n",
        "\n",
        "personsMapping = {\"2\": 2, \"4\": 4, \"more\": 6}\n",
        "dataFrame[\"persons\"] = dataFrame[\"persons\"].map(personsMapping)\n",
        "\n",
        "lugBootMapping = {\"small\": 1, \"med\": 2, \"big\": 3}\n",
        "dataFrame[\"lug_boot\"] = dataFrame[\"lug_boot\"].map(lugBootMapping)\n",
        "\n",
        "safetyMapping = {\"low\": 1, \"med\": 2, \"high\": 3}\n",
        "dataFrame[\"safety\"] = dataFrame[\"safety\"].map(safetyMapping)\n",
        "\n",
        "dataFrameTrain, dataFrameTest = trainTestSplit(dataFrame, testSize = 0.3)\n",
        "\n",
        "print(\"Random Forest - Car Evaluation Dataset\")\n",
        "print(\"  Maximum bootstrap size (n) is {}\".format(dataFrameTrain.shape[0]))\n",
        "print(\"  Maximum random subspace size (d) is {}\".format(dataFrameTrain.shape[1] - 1))"
      ],
      "metadata": {
        "id": "lXEhUEvoncmq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d229029-26ca-4781-c215-2f4a9c5d975f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest - Car Evaluation Dataset\n",
            "  Maximum bootstrap size (n) is 1210\n",
            "  Maximum random subspace size (d) is 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "startTime = time.time()\n",
        "randomForest = createRandomForest(dataFrameTrain, bootstrapSize = 1000, forestSize = 10, treeMaxDepth = 8)\n",
        "buildingTime = time.time() - startTime\n",
        "randomForestTestResults = randomForestPredictions(dataFrameTest, randomForest)\n",
        "accuracyTest = calculateAccuracy(randomForestTestResults, dataFrameTest.iloc[:, -1]) * 100\n",
        "randomForestTrainResults = randomForestPredictions(dataFrameTrain, randomForest)\n",
        "accuracyTrain = calculateAccuracy(randomForestTrainResults, dataFrameTrain.iloc[:, -1]) * 100\n",
        "print(\"  n = {}, k = {}, maxDepth = {}:\".format(1000, 10, 8))\n",
        "print(\"    accTest = {0:.2f}%, \".format(accuracyTest), end = \"\")\n",
        "print(\"accTrain = {0:.2f}%, \".format(accuracyTrain), end = \"\")\n",
        "print(\"buildTime = {0:.2f}s\".format(buildingTime), end = \"\\n\")"
      ],
      "metadata": {
        "id": "F1buQncRpDBw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b119364f-c2e0-4afd-c374-4c1bb03b9236"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AVG time to build a Decision Tree = 0.1448500156402588\n",
            "  n = 1000, k = 10, maxDepth = 8:\n",
            "    accTest = 82.63%, accTrain = 89.26%, buildTime = 1.46s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run with breastCancer dataset"
      ],
      "metadata": {
        "id": "fn5KZ9CMpcdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataFrame = pd.read_csv(\"/content/drive/MyDrive/Bài Tập Về Nhà Môn Cuối/random-forest-from-scratch-main/dataset_files/breast_cancer.csv\")\n",
        "dataFrame = dataFrame.drop(\"id\", axis = 1)\n",
        "dataFrame = dataFrame[dataFrame.columns.tolist()[1: ] + dataFrame.columns.tolist()[0: 1]]\n",
        "dataFrameTrain, dataFrameTest = trainTestSplit(dataFrame, testSize = 0.25)\n",
        "\n",
        "print(\"Random Forest - Breast Cancer Dataset\")\n",
        "print(\"  Maximum bootstrap size (n) is {}\".format(dataFrameTrain.shape[0]))\n",
        "print(\"  Maximum random subspace size (d) is {}\".format(dataFrameTrain.shape[1] - 1))"
      ],
      "metadata": {
        "id": "NyTiCrX0paf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd3b267c-03cd-4324-e9a6-395fef772b37"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest - Breast Cancer Dataset\n",
            "  Maximum bootstrap size (n) is 427\n",
            "  Maximum random subspace size (d) is 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "startTime = time.time()\n",
        "randomForest = createRandomForest(dataFrameTrain, bootstrapSize = 60, forestSize = 30, treeMaxDepth = 3)\n",
        "buildingTime = time.time() - startTime\n",
        "randomForestTestResults = randomForestPredictions(dataFrameTest, randomForest)\n",
        "accuracyTest = calculateAccuracy(randomForestTestResults, dataFrameTest.iloc[:, -1]) * 100\n",
        "randomForestTrainResults = randomForestPredictions(dataFrameTrain, randomForest)\n",
        "accuracyTrain = calculateAccuracy(randomForestTrainResults, dataFrameTrain.iloc[:, -1]) * 100\n",
        "print(\"  n = {}, k = {}, maxDepth = {}:\".format(60, 30, 3))\n",
        "print(\"    accTest = {0:.2f}%, \".format(accuracyTest), end = \"\")\n",
        "print(\"accTrain = {0:.2f}%, \".format(accuracyTrain), end = \"\")\n",
        "print(\"buildTime = {0:.2f}s\".format(buildingTime), end = \"\\n\")"
      ],
      "metadata": {
        "id": "_Gqc2jyIqFkw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4922fbc7-0b29-49c9-a83d-8c9c57469ae3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AVG time to build a Decision Tree = 0.6458845297495525\n",
            "  n = 60, k = 30, maxDepth = 3:\n",
            "    accTest = 92.96%, accTrain = 94.15%, buildTime = 19.40s\n"
          ]
        }
      ]
    }
  ]
}